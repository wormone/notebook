<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A notebook on data analysis in python</title>
    <link>https://wormone.github.io/notebook/index.xml</link>
    <description>Recent content on A notebook on data analysis in python</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 27 Sep 2017 19:21:15 +0800</lastBuildDate>
    <atom:link href="https://wormone.github.io/notebook/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>基于DBSCAN的探索性气候分析</title>
      <link>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8EDBSCAN%E7%9A%84%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%B0%94%E5%80%99%E5%88%86%E6%9E%90/</link>
      <pubDate>Wed, 27 Sep 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8EDBSCAN%E7%9A%84%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%B0%94%E5%80%99%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;&lt;strong&gt;数据挖掘&lt;/strong&gt;是在大型数据存储库中，自动的发现有用信息的过程。数据挖掘技术用来探查大型数据库，发现先前未知的有用模式。&lt;/p&gt;

&lt;p&gt;数据挖掘的任务分为两大类：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;预测任务。目标是根据其它属性的值，预测特定属性的值。&lt;/li&gt;
&lt;li&gt;描述任务。目标是导出概括数据中潜在联系的模式（相关、趋势、聚类、轨迹和异常）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;气象数据是天然的大数据，气象数据的分析研究其实都在遵循数据挖掘的规则，或者说是数据挖掘在这一特定领域的应用。&lt;/p&gt;

&lt;p&gt;大家知道，时空分布和变化是气象的基本属性和特征，对时空分布和变化的分析一直以来都是气象学研究关注的重点之一。常用的分析方法如：时间序列分析、高级谱分析、时空变量场的EOF、SVD、CCA分析等。不同的方法适用于不同的问题。&lt;/p&gt;

&lt;p&gt;关于气候分区的研究已经有很多了，但往往受限于数据和方法，我们对很多问题的认识仍然是有限的。&lt;/p&gt;

&lt;p&gt;今天这里的一个示例是基于DBSCAN聚类分析对降水量的气候特征进行一些探索性的分析。&lt;/p&gt;

&lt;p&gt;DBSCAN是一种简单、有效的基于&lt;strong&gt;密度&lt;/strong&gt;的聚类算法，&lt;strong&gt;寻找被低密度区域分离的高密度区域&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我们对中国160个站1951-2016年夏季（JJA）降水量来做一些分析。距离的度量采用&lt;strong&gt;correlation&lt;/strong&gt;（注意不能用欧式距离）。两个参数Eps和MinPts，实验性的分别尝试[0.3, 0.4, 0.5, 0.6, 0.7]和[3, 4, 5, 6, 7, 8]。Eps是距离半径的阈值，MinPts是点个数的阈值。因此我们刚刚设定的参数搜索范围也就是相关性在0.7~0.3之间，簇内最少站点个数在3~8之间。&lt;/p&gt;

&lt;p&gt;由于DBSCAN使用簇的基于密度的定义，因此它是相对抗噪声的，并且能够处理任意形状和大小的簇，可以发现KMeans不能发现的很多簇。这是它的一个优点。&lt;/p&gt;

&lt;p&gt;以下是我们得到的一些有意思的结果（时间来不及了，回头再解释）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;DBSCAN_out_0.5_8.png&#34; alt=&#34;Eps=0.5, MinPts=8&#34; title=&#34;DBSCAN_out_0.5_8&#34; /&gt;
&lt;img src=&#34;DBSCAN_out_0.5_5.png&#34; alt=&#34;Eps=0.5, MinPts=5&#34; title=&#34;DBSCAN_out_0.5_5&#34; /&gt;
&lt;img src=&#34;DBSCAN_out_0.5_4.png&#34; alt=&#34;Eps=0.5, MinPts=4&#34; title=&#34;DBSCAN_out_0.5_4&#34; /&gt;
&lt;img src=&#34;DBSCAN_out_0.4_3.png&#34; alt=&#34;Eps=0.4, MinPts=3&#34; title=&#34;DBSCAN_out_0.4_3&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>看纪录片《地球起源HowTheEarthWasMade》</title>
      <link>https://wormone.github.io/notebook/post/%E7%9C%8B%E7%BA%AA%E5%BD%95%E7%89%87%E3%80%8A%E5%9C%B0%E7%90%83%E8%B5%B7%E6%BA%90HowTheEarthWasMade%E3%80%8B/</link>
      <pubDate>Wed, 13 Sep 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E7%9C%8B%E7%BA%AA%E5%BD%95%E7%89%87%E3%80%8A%E5%9C%B0%E7%90%83%E8%B5%B7%E6%BA%90HowTheEarthWasMade%E3%80%8B/</guid>
      <description>&lt;p&gt;这一集讲的是北美五大湖的形成。&lt;/p&gt;

&lt;p&gt;在我们普通人的眼里，我们游玩的山水风景都是不变的景观。其实任何一个地方的自然环境都是在不断演变着的，只是因为当我们用自己的的时间尺度来衡量时，这些变化显得&lt;strong&gt;太小&lt;/strong&gt;或者&lt;strong&gt;太慢&lt;/strong&gt;以至于被忽略了。&lt;/p&gt;

&lt;p&gt;然而，在地质学家眼中，一切都不同了。最早研究北美五大湖的地质学家测量发现，大瀑布每年以0.3米的速度侵蚀岩石，并由此推算出了五大湖的形成时间（再后来的研究发现侵蚀速度是每年0.9米）。在地质学家的眼里，如今的一切都是&lt;strong&gt;动态演变过程&lt;/strong&gt;中的一个微小&lt;strong&gt;片段&lt;/strong&gt;，地貌特征、地层结构、古生物化石、岩石类型、沉积物等等都无时无刻不伴随着这种演变，因而蕴藏着这种演变的秘密——它的&lt;strong&gt;过去和未来&lt;/strong&gt;！&lt;/p&gt;

&lt;p&gt;湖盆下的巨大盐矿、湖盆的白云岩、地表冰丘地貌、海洋生物化石、岩石上的冰川擦痕、古河系……当地质学家把越来越多的证据汇集起来，就能够推测出北美五大湖的形成过程，揭示出那些巨大的变迁。更有意思的是，如今令人担忧的五大湖湖水水位下降竟然是缘于“地表回弹”——过去被厚厚冰盖重重压低下沉的地表，当冰盖消失后正在回弹，海拔上升，流入湖中的河水减少甚至将会停止……&lt;/p&gt;

&lt;p&gt;其实，在地球自然环境变迁的背后，始终有一个无可匹敌的巨大推动力。它就是太阳。确切的说，不是太阳本身，而是地球接收的太阳辐射的变化。太阳活动、地球轨道参数、黄赤交角、大陆漂移、火山喷发的火山灰进入大气层形成的阳伞效应等等，这些都会影响地球上接收到的太阳辐射变化。&lt;strong&gt;辐射平衡&lt;/strong&gt;是地球气候系统形成的重要基础，辐射平衡的改变也就改变了气候，冷暖、干湿。终极一切奥秘，肯定都在天文宇宙之中。人类太渺小了，太短暂了，太微不足道了……&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习与环境气象：空气质量预报：4业务生产</title>
      <link>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A4%E4%B8%9A%E5%8A%A1%E7%94%9F%E4%BA%A7/</link>
      <pubDate>Fri, 21 Jul 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A4%E4%B8%9A%E5%8A%A1%E7%94%9F%E4%BA%A7/</guid>
      <description>&lt;p&gt;建立模型和方案的最终目的是能够应用于未来每天的实际预测业务生产中。因此，&lt;strong&gt;很重要的一点&lt;/strong&gt;必须记住，那就是未来可用于预测的特征必须能够和之前建模训练时采用的特征保持完全一致。也就是说，如果建模训练时采用的特征在后来不可获取了，那么模型也就无法应用到实际的日常生产中去了。所以，在建模训练的时候就必须关注这个问题。在条件不能再满足的情况下，重新建模训练甚至重新做特征工程都是有可能的。&lt;/p&gt;

&lt;p&gt;模型方案确定可行之后，要做的就是业务化部署了。这一部份工作就是对预报方案的封装，然后设定定时自动化任务并记录运行日志。如果是在linux系统上，crontab较为常用。如果实在windows上，也可以配置任务计划。此外，python也有软件包（常用apscheduler）可以做定时任务配置。&lt;/p&gt;

&lt;p&gt;既然是业务化生产，就要监控各种可能出现的异常情况，用python的logging模块可以很好的承担这个工作。对于各种异常情况造成的数据缺失情况，也应有相应的处理措施，具体问题需要具体分析，以保障日常生产。&lt;/p&gt;

&lt;p&gt;作为完整的业务流程，每天的预报结果通常以文件存储或写入数据库，这些方法一并封装在程序中就可以了。用python做这些工作通常都是非常简单的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习与环境气象：空气质量预报：3建模、训练和评估</title>
      <link>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A3%E5%BB%BA%E6%A8%A1%E3%80%81%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0/</link>
      <pubDate>Thu, 20 Jul 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A3%E5%BB%BA%E6%A8%A1%E3%80%81%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0/</guid>
      <description>&lt;p&gt;Python有很多机器学习方面的软件包（scikit-learn、TensorFlow、Keras等），对于我们应用于构建和训练模型都是非常方便的，官方文档就是很好的示例。工具都有了，剩下的问题就是具体问题具体分析，从理论角度&lt;strong&gt;选取合适的模型和方案&lt;/strong&gt;，然后尝试训练和评估模型的表现，最后获得可以用于日常生产的模型和方案。&lt;/p&gt;

&lt;p&gt;拿我们现在的空气质量预报问题来说，对于某一种污染物或者空气质量指数AQI，其伴随的天气特征是多元的，其关系可以是线性的也可以是非线性的。&lt;strong&gt;从适用的模型上来说&lt;/strong&gt;，人工神经网络模型、基于统计学的广义线性模型、基于决策树的集合方法，都可以尝试。&lt;strong&gt;从适用的方案上来说&lt;/strong&gt;，不同时空（不同地区、不同季节）匹配的条件下，空气质量与天气条件的关系也会不同，因此，对于不同地区、不同季节，应当分别进行建模、训练和评估。&lt;/p&gt;

&lt;p&gt;在实际运用于生产业务的时候，气象上还通常采用&lt;strong&gt;滚动预报&lt;/strong&gt;的方法，比如每天用之前一段时间的数据进行建模并用于未来若干天的预报。&lt;/p&gt;

&lt;p&gt;预报效果怎么样，模型和方案的评估就很重要。评估的对象取决于所关注的目标。一般，通过统计分析正确率、漏报率、空报率、均方根误差（RMSE）、平均绝对误差（MAE）等特征，可以做出较为全面的评估。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习与环境气象：空气质量预报：2数据处理</title>
      <link>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A2%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link>
      <pubDate>Wed, 19 Jul 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A2%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid>
      <description>&lt;p&gt;检查完数据质量问题，就要对发现的必要问题进行处理了。其中最重要的问题就是&lt;strong&gt;数据缺失或异常&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于发现的数据缺失或异常，如果其样本量不大，而且可以利用时间和空间关系进行&lt;strong&gt;插补&lt;/strong&gt;的话，那么还算比较好的情况，也是我们比较期望出现并能解决的情况。如果数据缺失或异常的样本量比较大，或者其它原因导致无法进行合理插补以弥补此类数据质量问题，那么我们很可能要被迫放弃这些数据，其后果是可能导致后续工作受到严重限制甚至无法进行，这是我们最头疼的清醒，但愿不要出现。&lt;/p&gt;

&lt;p&gt;在处理完数据质量问题之后，我们要做的工作就是对数据进行必要的转换，也就是进一步信息化，以便后续的模型构建和训练工作。因此，这一步要做的工作是非常重要的，如果没有做好&lt;strong&gt;必要的、合理的&lt;/strong&gt;数据转换工作，后续工作可能就无法取得比较理想的结果。&lt;/p&gt;

&lt;p&gt;以天气预报信息为例，风向（东南西北风）可以转换为数字标号或者360度，风力（微风、3-4级）可以转换为数字标号或者特定风速数值m/s，天气现象（晴、多云、阴、雨雪等等）则通常转换为0、1标签（0表示没出现，1表示有出现）。这些是原始信息的基本转换工作。&lt;/p&gt;

&lt;p&gt;还有一部分转换工作在于从专业角度分析影响结果的哪些&lt;strong&gt;特征&lt;/strong&gt;可以被提取出来。以我们现在的空气质量预报来说，天气条件不仅仅是当时的数值，&lt;strong&gt;天气的变化信息&lt;/strong&gt;反而更为重要，这就需要我们把他们从原始数据中萃取出来。比如，24小时的气温和气压变化、一天当中气温的日较差、风向的变化等等，它们对于空气质量来说，都可能是重要的影响的因素。换句话说，空气质量这样或者那样，伴随着的是这样或者那样的天气特征。因此，这一部分工作，就是机器学习中所说的&lt;strong&gt;特征工程&lt;/strong&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习与环境气象：空气质量预报：1爬取数据</title>
      <link>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A1%E7%88%AC%E5%8F%96%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Tue, 18 Jul 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A1%E7%88%AC%E5%8F%96%E6%95%B0%E6%8D%AE/</guid>
      <description>&lt;p&gt;从网上爬取数据是获取数据的重要途径，相比于文本类型的数据（比如用户评论），气象和环境方面的数据多以数字为主，爬取似乎简单一些。但是对于我们做研究来说，数据的完整性就比较重要，如果数据质量不好，会比较让人头疼。空气质量监测数据的数据源很多，官方的是环保总站公布的数据，还有很多第三方提供数据接口，可以仔细看看，选择&lt;strong&gt;数据质量好的、来源稳定的&lt;/strong&gt;。天气数据来源也很多，比如中国天气网官网，另外也有很多第三方数据源可以获取（他们的数据大多也来自气象部门，差别不大），也要选取&lt;strong&gt;数据质量好的、来源稳定的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于我们的问题来说，有一点需要&lt;strong&gt;特别注意&lt;/strong&gt;，那就是无论气象数据还是空气质量数据，不光要有每天实时更新的数据（天气预报数据和空气质量实况数据），还需要有历史实况数据。还好这样的数据源都是可以找到的。&lt;/p&gt;

&lt;p&gt;数据爬取之前需要做的是仔细分析一下数据来源，这可能会大大减少爬取数据的工作量。比如，如果同一数据源，即有电脑浏览器页面又有手机浏览器页面，那么手机浏览器页面一般比较简单，容易分析。再比如，对于Ajax加载的数据，利用浏览器自带的工具仔细分析一下数据来源的请求，比调上来就调用Selenium要简单得多。&lt;/p&gt;

&lt;p&gt;Python的话，我们直接采用requests这个工具就可以很轻松完成数据爬取的工作了。&lt;/p&gt;

&lt;p&gt;爬下来的数据格式可能不是我们想要的，那么接下来要做的工作就是必要的格式转换。通常，json和csv都是很不错的格式。如果数据量比较大，还可以考虑用数据库来存储，对于简单一些的应用，sqlite就够了。对于数据处理，python的numpy和pandas通常都是很好用的工具。对于数据的预览（人工检视），用matplotlib画个曲线图出来看看是很直观的。另外，还可以从数据的基本统计信息来检查数据质量（特别是数据缺失和异常），比如最大最小值、平均值、样本数、方差等等，对于排查数据质量问题都有帮助。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习与环境气象：空气质量预报：0方案设计</title>
      <link>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A0%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Mon, 17 Jul 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%B0%94%E8%B1%A1%EF%BC%9A%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E9%A2%84%E6%8A%A5%EF%BC%9A0%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/</guid>
      <description>&lt;p&gt;现在到处都是人工智能和机器学习的新闻，气象也在凑热闹。看热闹的不怕事大，我们也来围观。&lt;/p&gt;

&lt;p&gt;话说回来，其实，机器学习在气象预报方面的能力是不能跟在图像语音识别等方面相比的。道理很简单，图像语音识别这类问题是比较明确的，&lt;strong&gt;不确定性&lt;/strong&gt;很小，人工的识别准确率很高，机器学好了可以更高更快。气象预报就不一样了，不管是人工基于天气学原理的分析还是计算机基于数学物理模型的的预报，准确率的水平都不能跟图像语音识别这类问题相比，不确定性还是太高了。如果说机器学习在气象上有好的应用方面的话，一定是那些不确定性相对比较小的地方（比如基于雷达回波的短临天气预报），或者数学物理模型还无法描述的地方（比如气候预测），也许能够取得比常规方法好一些的结果。能好多少，不知道，但是不会有本质的飞跃。&lt;/p&gt;

&lt;p&gt;这里我们做一点简单的工作，基于机器学习的方法来试着做做空气质量预报。&lt;strong&gt;总体思路&lt;/strong&gt;是这样的：从网上获取空气质量的历史数据和实时更新的监测数据，从网上获取天气实况的历史数据和实时更新的天气预报数据，用机器学习的方法发掘空气质量和气象条件之间的关联，构建基于气象因素的空气质量预报模型，最后用天气预报来预测未来同期的空气质量。所以我们的工作分为以下几个部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;爬取空气质量和天气数据。&lt;/li&gt;
&lt;li&gt;数据信息的转换（为构建和训练模型做准备）。&lt;/li&gt;
&lt;li&gt;尝试构建和训练模型，并进行评估。&lt;/li&gt;
&lt;li&gt;实际运用于日常预报工作，实现自动化运作。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let&amp;rsquo;s GO！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>K-means聚类分析应用示例</title>
      <link>https://wormone.github.io/notebook/post/K-means%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</link>
      <pubDate>Tue, 13 Jun 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/K-means%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</guid>
      <description>&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python
# -*- coding: utf-8 -*-

&#39;&#39;&#39;KMeans 聚类分析样例程序

关于样本和样本（点和点）之间距离的算法：
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html#sklearn.metrics.pairwise.pairwise_distances

用 silhouette 评估 KMeans 聚类分析，画图，确定分类数目：
http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py

在 KMeans 之前先用主成分分析（PCA）降维：
http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py

&#39;&#39;&#39;


import numpy as np
import matplotlib.cm as cm
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances, silhouette_score, silhouette_samples


# 载入样例数据
from sklearn import datasets
dataset = datasets.load_iris()
X = dataset.data
# y = dataset.target  # 这是实际分类标签。由于 KMeans 是非监督（自动）分类算法，因此不用学习这个真实分类。
n_samples, n_features = X.shape
print(&#39;n_samples = {}, n_features = {}&#39;.format(n_samples, n_features))


&amp;quot;&amp;quot;&amp;quot;
    需要特别注意的是：这里的样例数据比较简单，每个样本的不同特征的量纲和数量级相同，但是我们要面对的问题可能不是这样：
    一天（看作一个样本、一个点）的特征有风速风向、最高最低气温、湿度、气压，及其24小时变化值等，
    不同要素的量纲和数量级不同，因此最好在进行 KMeans 聚类分析之前，先对每个要素进行标注化或归一化处理。
    归一化即 (x-min(x))/(max(x)-min(x))，把 x 转变为 [0, 1] 区间内。
    标准化即 (x-mean(x))/std(x)，结果有正有负，标准差变为 1。
&amp;quot;&amp;quot;&amp;quot;


&amp;quot;&amp;quot;&amp;quot; 
    以下两个 KMeans 样例程序，都是把示例数据 X 分成 3 类 
&amp;quot;&amp;quot;&amp;quot;


def test_KMeans_default(X=X, n_clusters=3):
    # 直接采用 KMeans 进行聚类分析，默认距离计算方法是 euclidean，即欧几里得距离
    kmeans_model = KMeans(n_clusters=n_clusters, random_state=1).fit(X)
    cluster_labels = kmeans_model.labels_
    silhouette_avg = silhouette_score(X, cluster_labels, metric=&#39;euclidean&#39;)
    sample_silhouette_values = silhouette_samples(X, cluster_labels, metric=&#39;euclidean&#39;)
    # print sample_silhouette_values
    print(&#39;Average silhouette value: {}&#39;.format(silhouette_avg))


def test_KMeans_using_custom_distance(X=X, n_clusters=3, metric=&#39;correlation&#39;):
    # 先按照某种距离计算方法计算距离矩阵 D，如采用 correlation 算法，即 1 减去皮尔逊相关系数，这种算法在我们需要解决的问题中更常用
    D = pairwise_distances(X, metric=metric)
    clusterer = KMeans(n_clusters=n_clusters, random_state=1, precompute_distances=True)
    cluster_labels = clusterer.fit_predict(D)
    silhouette_avg = silhouette_score(D, cluster_labels, metric=&#39;precomputed&#39;)
    sample_silhouette_values = silhouette_samples(D, cluster_labels, metric=&#39;precomputed&#39;)
    # print sample_silhouette_values
    print(&#39;Average silhouette value: {}&#39;.format(silhouette_avg))

    &amp;quot;&amp;quot;&amp;quot;
        以下绘图程序复制粘贴自官网示例，样例数据 X 只有 4 个特征，因此右侧的图能看出分类。
        对于高维度的气象数据而言，例如，一天（看作一个样本、一个点）的特征有风速风向、最高最低气温、湿度、气压，及其24小时变化值等，
        因此，无法在简单的二维平面显示他们的分类：画出来的点，虽然属于不同类别，但是都会叠在一起，分不出来。
    &amp;quot;&amp;quot;&amp;quot;
    # Create a subplot with 1 row and 2 columns
    fig, (ax1, ax2) = plt.subplots(1, 2)
    fig.set_size_inches(18, 7)

    # The 1st subplot is the silhouette plot
    # The silhouette coefficient can range from -1, 1 but in this example all
    # lie within [-0.1, 1]
    ax1.set_xlim([-0.1, 1])
    # The (n_clusters+1)*10 is for inserting blank space between silhouette
    # plots of individual clusters, to demarcate them clearly.
    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])

    y_lower = 10
    for i in range(n_clusters):
        # Aggregate the silhouette scores for samples belonging to
        # cluster i, and sort them
        ith_cluster_silhouette_values = \
            sample_silhouette_values[cluster_labels == i]

        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        color = cm.spectral(float(i) / n_clusters)
        ax1.fill_betweenx(np.arange(y_lower, y_upper),
                          0, ith_cluster_silhouette_values,
                          facecolor=color, edgecolor=color, alpha=0.7)

        # Label the silhouette plots with their cluster numbers at the middle
        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

        # Compute the new y_lower for next plot
        y_lower = y_upper + 10  # 10 for the 0 samples

    ax1.set_title(&amp;quot;The silhouette plot for the various clusters.&amp;quot;)
    ax1.set_xlabel(&amp;quot;The silhouette coefficient values&amp;quot;)
    ax1.set_ylabel(&amp;quot;Cluster label&amp;quot;)

    # The vertical line for average silhouette score of all the values
    ax1.axvline(x=silhouette_avg, color=&amp;quot;red&amp;quot;, linestyle=&amp;quot;--&amp;quot;)

    ax1.set_yticks([])  # Clear the yaxis labels / ticks
    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])

    # # 2nd Plot showing the actual clusters formed
    # colors = cm.spectral(cluster_labels.astype(float) / n_clusters)
    # ax2.scatter(X[:, 1], X[:, 2], marker=&#39;.&#39;, s=30, lw=0, alpha=0.7,
    #             c=colors)

    # # Labeling the clusters
    # centers = clusterer.cluster_centers_
    # # Draw white circles at cluster centers
    # ax2.scatter(centers[:, 0], centers[:, 1],
    #             marker=&#39;o&#39;, c=&amp;quot;white&amp;quot;, alpha=1, s=200)

    # for i, c in enumerate(centers):
    #     ax2.scatter(c[0], c[1], marker=&#39;$%d$&#39; % i, alpha=1, s=50)

    # ax2.set_title(&amp;quot;The visualization of the clustered data.&amp;quot;)
    # ax2.set_xlabel(&amp;quot;Feature space for the 1st feature&amp;quot;)
    # ax2.set_ylabel(&amp;quot;Feature space for the 2nd feature&amp;quot;)

    # plt.suptitle((&amp;quot;Silhouette analysis for KMeans clustering on sample data &amp;quot;
    #               &amp;quot;with n_clusters = %d&amp;quot; % n_clusters),
    #              fontsize=14, fontweight=&#39;bold&#39;)

    plt.show()


if __name__ == &#39;__main__&#39;:
    # test_KMeans_using_custom_distance(metric=&#39;euclidean&#39;)
    test_KMeans_using_custom_distance()

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>气象数据查询接口设计的简要方案</title>
      <link>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%AE%80%E8%A6%81%E6%96%B9%E6%A1%88/</link>
      <pubDate>Thu, 13 Apr 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%AE%80%E8%A6%81%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;p&gt;这里我们指的是存储在数据库里的&lt;strong&gt;站点气象数据&lt;/strong&gt;，存储在文件中的格点数据是另一回事了。&lt;/p&gt;

&lt;p&gt;气象数据的特点是包括时间、地点、层次、要素等&lt;strong&gt;多个维度&lt;/strong&gt;，通常以特定文本格式存储的数据不便于数据的提取和查询，尤其当这种提取和查询经常发生的时候。因此，导入关系型数据库，然后编写查询方法，对用户提供查询服务就是非常必要的了。&lt;/p&gt;

&lt;p&gt;通常，数据源的格式是固定的，而且随着时间的延伸，数据会不断更新，那么编写一套数据读取和写入数据库的程序就会方便后续的数据更新工作了。&lt;/p&gt;

&lt;p&gt;python操作数据库有&lt;strong&gt;两种方式&lt;/strong&gt;，一种是不同数据库采用不同的软件包（如对于MS SQL可以使用pymssql，对于MySQL可以使用pymysql，对于sqlite可以使用sqlite3），一种是基于对象-关系映射模型（ORM）的软件包（如SQLAlchemy）。两种方式都是比较容易的，官方文档都有很好的示例，参照按部就班写就可以了。使用SQLAlchemy的好处是可以更容易的切换不同数据库。&lt;/p&gt;

&lt;p&gt;数据库表的设计应当看数据的具体情况，具体分析，没有太多可说的。当写入和读取数据库数据的方法写好之后，就是后续的调用和封装工作了。读取的方法有哪些，取决于查询的需求有哪些，一一对应就可以了。通常，查询都包括时间范围、空间范围、要素名称、统计方式（如平均值、累计值、最大最小值）等方面。&lt;/p&gt;

&lt;p&gt;接下来就是对外提供数据查询服务了，可能直接被用户调用，也可能被其它外部程序调用。数据查询接口一般只涉及到数据的读取，很少涉及到数据的写入，因此来说功能比较单一，实现起来也比较容易。对于上述写好的读取方法，只需要利用HTTP服务封装一下就可以了。我们采用&lt;strong&gt;Flask&lt;/strong&gt;或&lt;strong&gt;Tornado&lt;/strong&gt;框架就可以很轻松完成任务了，其中需要注意的基本问题包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;url的设计应符合约定俗成的规范，清晰明了。&lt;/li&gt;
&lt;li&gt;只编写和允许必要的请求方法，禁止不必要的请求。&lt;/li&gt;
&lt;li&gt;接口说明文档应编写好并放在一个类似/api/help的url里以便用户查阅。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进一步，可能遇到的问题包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果有查询不同结果格式的需求，应在查询结果之后增加一个统一的格式处理方法。&lt;/li&gt;
&lt;li&gt;如果有区分用户权限的功能需求，应在查询方法之前增加一个权限管理模块。&lt;/li&gt;
&lt;li&gt;如果有提高服务的性能的需求，应相应的从硬件配置、缓方式、多任务并行等方面解决。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>气象数据处理和绘图常用的python软件包</title>
      <link>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E7%BB%98%E5%9B%BE%E5%B8%B8%E7%94%A8%E7%9A%84python%E8%BD%AF%E4%BB%B6%E5%8C%85/</link>
      <pubDate>Fri, 13 Jan 2017 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E7%BB%98%E5%9B%BE%E5%B8%B8%E7%94%A8%E7%9A%84python%E8%BD%AF%E4%BB%B6%E5%8C%85/</guid>
      <description>

&lt;h3 id=&#34;1-基本问题&#34;&gt;1. 基本问题&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- datetime, canlendar：时间和日期处理
- re：正则处理
- glob：文件名匹配
- os, shutil：系统路径等操作
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-特定格式&#34;&gt;2. 特定格式&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- netCDF4：netCDF数据读写
- pygrib：grib数据读写
- struct：二进制数据读写
- gdal：geotiff等数据读写
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-计算分析&#34;&gt;3. 计算分析&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- numpy, scipy：科学计算
- pandas：数据结构框架
- scikit-learn：统计学和机器学习模型
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-绘图&#34;&gt;4. 绘图&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- matplotlib, basemap：几乎所有类别的气象图形
- seaborn：更美观一些的图形
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-业务自动化&#34;&gt;5. 业务自动化&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- apscheduler：定时任务管理
- multiprocessing：多进程并行计算
- celery：分布式并行框架
- logging：日志记录
- pyWRF：WRF管理
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>基于leaflet.js的气象数据可视化方案</title>
      <link>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8Eleaflet.js%E7%9A%84%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 13 Nov 2016 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8Eleaflet.js%E7%9A%84%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;p&gt;气象数据是多维度的数据，包括时间、空间、要素名等。空间属性是气象数据的基本属性。&lt;/p&gt;

&lt;p&gt;气象数据的可视化离不开空间分布的展示。单点数据以地理坐标为基础，通常在地图上以数据、符号、颜色等标识。例如风向通常以风杆或者带有方向箭头的小图标标识。网格化数据通常以等值线（contour）、填充色（contourf）或色块（imagesc，pcolor）标识。&lt;/p&gt;

&lt;p&gt;上述两类数据均可以用&lt;strong&gt;geojson&lt;/strong&gt;的格式组织起来交由&lt;strong&gt;leaflet.js&lt;/strong&gt;在页面上展示。&lt;/p&gt;

&lt;p&gt;单点的数据很简单。网格化数据是以等值线分析为基础的，这个工作可以交由我们熟悉的&lt;strong&gt;matplotlib&lt;/strong&gt;来完成，其输出结果再由&lt;strong&gt;geojsoncontour&lt;/strong&gt;这个第三方软件包转换为geojson格式即可（该软件包在github上可以找到，其中的一个小bug已被我们修复）。&lt;/p&gt;

&lt;p&gt;leaflet.js提供了丰富的方法用户展示基于GIS的信息，并提供了很多交互操作的功能，官方文档都有很好的示例。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基于机器学习的组合方法的气候预测</title>
      <link>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%BB%84%E5%90%88%E6%96%B9%E6%B3%95%E7%9A%84%E6%B0%94%E5%80%99%E9%A2%84%E6%B5%8B/</link>
      <pubDate>Thu, 13 Oct 2016 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%BB%84%E5%90%88%E6%96%B9%E6%B3%95%E7%9A%84%E6%B0%94%E5%80%99%E9%A2%84%E6%B5%8B/</guid>
      <description>

&lt;h3 id=&#34;1-气候预测的关键科学问题和方法&#34;&gt;1. 气候预测的关键科学问题和方法&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 关键科学问题
    - 气候系统：复杂的、高度非线性的、开放的巨系统
    - 气候系统的可预报性：外部强迫和内部过程
- 预测方法
    - 统计学：统计气候学
    - 数值模式：气候系统物理模型的数学描述和计算机应用
    - 动力统计：数值模式 + 统计学
    - 机器学习额
        - 机器学习是让计算机程序随着经验积累自动提高性能
        - 机器学习与统计学的联系和区别
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-机器学习-vs-统计学&#34;&gt;2. 机器学习 Vs 统计学&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 统计学和机器学习的文化差异和本质区别
    - 统计学更关心模型的可解释性
        更多是关于问题本质的一个个检验，
        目标是建立一个可以解释的问题的模型，
        然而很多问题的复杂性使得严谨的统计模型无法被构建出来。
    - 机器学习更关心模型的预测能力
        目标是搭建一套高效可靠的系统，
        能够持续的预测未来并且稳定的工作，
        即使这种预测缺乏完美的解释。
- 机器学习与统计学是互补的吗？
    - http://synchuman.baijia.baidu.com/article/283931
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-机器学习的组合方法&#34;&gt;3. 机器学习的组合方法&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 组合的目的
    - 将若干基于某种算法的估计结合起来，从而提高泛化能力
- 组合方法的分类和举例
    - 均值法（Averaging methods）
        - 装袋（Bagging）
        - 随机森林（Forests of randomized trees）
    - 提升法（Boosting methods）
        - 自适应提升（AdaBoost）
        - 梯度树提升（Gradient Tree Boosting）
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-中国降水的气候预测试验&#34;&gt;4. 中国降水的气候预测试验&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 基础数据
    - 中国 160 个国际气候交换站 1951 年 1 月至今逐月降水量
    - 百项气候系统指数集：88 项大气环流指数、26 项海温指数、16 项其他指数
- 关键技术：以夏季（JJA）降水量预测为例
    - 设定预测目标
        - 以各站当年夏季降水量为原始目标
        - 以 1981-2010 为气候基准期，计算历年夏季降水量距平百分率
        - 以某种标准将降水量划分为若干等级作为预测目标 Y
    - 预测因子筛选
        - 以前一年 7 月至当年 4 月各项气候系统指数为候选因子
        - 计算 Pearson 相关系数和 Spearman 相关系数，并进行显著性检验
        - 通过显著性检验的因子构成预测因子 X
    - 组合方法和交叉验证
        - 构建组合分类器
            - 均值法：Bagging, RandomForest, ExtraTrees
            - 提升法：AdaBoost, GradientBoosting
        - 交叉验证（分类器性能评价）
            - 样本时段：1951-2010 共 60 年
            - 迭代器：采用 Stratified k-fold
            - 计算交叉验证得分 S
            - S 减去气候概率，即为预测技巧得分
    - 业务化方案
        - 每年年初开始自动发布当年夏季降水量预测
        - 单站预测和区域分布图均可自动化制作
        - 组合方法同时可以预测出单站各降水等级出现的概率
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>气象开发常用的开源软件技术</title>
      <link>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Tue, 13 Sep 2016 19:21:15 +0800</pubDate>
      
      <guid>https://wormone.github.io/notebook/post/%E6%B0%94%E8%B1%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E6%8A%80%E6%9C%AF/</guid>
      <description>

&lt;h3 id=&#34;1-基于python的科学计算&#34;&gt;1. 基于Python的科学计算&lt;/h3&gt;

&lt;p&gt;Python是一种面向对象的、动态的高级程序设计语言，具有非常简洁而清晰的语法，既可以用于快速开发脚本程序，也可以用于开发大规模的软件，特别适合于完成各种高层任务。&lt;/p&gt;

&lt;p&gt;随着Numpy、SciPy、Matplotlib、ETS等众多程序库的开发，Python越来越适合于做科学计算。与科学计算领域最流行的商业软件MATLAB相比，Python是一门真正的通用程序设计语言，比MATLAB所采用的脚本语言的应用范围更广泛，有更多程序库的支持，适用于Windows和Linux等多种平台，完全免费并且开放源代码。虽然MATLAB中的某些高级功能目前还无法替代，但是对于基础性、前瞻性的科研工作和应用系统开发，完全可以用Python来完成。&lt;/p&gt;

&lt;p&gt;Python的生态系统是非常完善的。在科学计算方面，Python有两个常用的发行版，即Python(x,y) 和 Anaconda。Python(x,y) 不仅包括了几乎所有的科学计算第三方程序集，还包括了用于科学计算开发的集成开发环境（IDE），如 Spider 和 Eclipse。Anaconda提供了基础和全集两种安装套件，并且在第三方程序集管理和python容器化环境管理方面更为出色。&lt;/p&gt;

&lt;p&gt;在科学计算、数据挖掘与机器学习、人工智能（AI）等专业领域，Python都具有相当广泛而深入的应用，美国海洋大气局（NOAA）、国家航空航天局（NASA）、谷歌，全世界其它非常多的机构、公司、数据科学家和工程师都在使用Python并且致力于为开源世界做贡献。&lt;/p&gt;

&lt;h3 id=&#34;2-基于matplotlib的二维数据分析&#34;&gt;2. 基于Matplotlib的二维数据分析&lt;/h3&gt;

&lt;p&gt;Matplotlib 是Python最著名的绘图库，它提供了一整套和 MATLAB 类似的绘图函数集，十分适合编写短小的脚本程序，进行快速绘图。此外，Matplotlib 采用面向对象技术来实现，因此组成图表的各个元素都是对象，在编写较大的应用程序时通过面向对象的方式使用 Matplotlib 将更加有效。&lt;/p&gt;

&lt;p&gt;Matplotlib 的文档十分完备，并且展示页面中有上百幅图表的缩略图即源程序。因此，如果需要绘制某种类型的图表，只需要在这个页面中浏览、选择、试验一下，基本上就能快速实现。对于不同的参数和更详细的设置，可以在线查阅官方文档。&lt;/p&gt;

&lt;p&gt;对于二维图形的绘制，本项目应用最多的便是等值线图或填充图。这里将采用面向对象的方式调用Contour/Contourf 函数的绘图结果，提取等值线、等值面的数字描述（转换为GeoJSON格式），作为WebGIS可视化的基础数据。&lt;/p&gt;

&lt;h3 id=&#34;3-基于leaflet的webgis应用&#34;&gt;3. 基于Leaflet的WebGIS应用&lt;/h3&gt;

&lt;p&gt;Leaflet 是对于移动端友好的一个用于创建动态交互地图的开源JavaScript程序库。Leaflet 非常轻量级，用于生产环境的程序只有33KB，但其中已经包含了几乎所有的地图特征功能，对于绝大多数地图应用而言都能胜任。&lt;/p&gt;

&lt;p&gt;Leaflet 始终本着设计简明、表现优异、高可用性的理念，使它能够非常高效的工作在所有主流移动端和桌面端设备上。Leaflet 有着诸多的第三方插件可以进行扩展，并且有着非常美观和易用的官方文档，其简单、可读性良好的源代码吸引着越来越多的机构和开发者为其做贡献。&lt;/p&gt;

&lt;p&gt;Leaflet 支持各种瓦片图层、矢量数据、位图覆盖叠加、GeoJSON，支持纯CSS3的信息框、基于图片或者HTML的地理标记、自定义的地图和控制接口、自定义的地图投影、功能强大的面向对象的类扩展，支持地图缩放、属性查询修改、图层切换和尺度变换，支持拖拽、平移、滚轮缩放、点击等丰富的交互功能，支持缩放和平移动画、瓦片和弹出框消失动画、美观的图层对象控制默认设计、超视网膜分辨率渲染，支持移动端硬件加速、纯CSS3平滑效果、敏捷的多边形渲染，模块化的构建系统高效而稳健，支持所有PC端和移动端主流Web浏览器。&lt;/p&gt;

&lt;h3 id=&#34;4-基于echarts的web图表&#34;&gt;4. 基于Echarts的Web图表&lt;/h3&gt;

&lt;p&gt;ECharts，缩写来自Enterprise Charts，商业级数据图表，一个开源的纯Javascript的图表库，可以流畅的运行在PC和移动设备上，兼容当前绝大部分浏览器，底层依赖轻量级的Canvas类库ZRender，提供直观，生动，可交互，可高度个性化定制的数据可视化图表。创新的拖拽重计算、数据视图、值域漫游等特性大大增强了用户体验，赋予了用户对数据进行挖掘、整合的能力。&lt;/p&gt;

&lt;p&gt;支持折线图（区域图）、柱状图（条状图）、散点图（气泡图）、K线图、饼图（环形图）、雷达图（填充雷达图）、和弦图、力导向布局图、地图、仪表盘、漏斗图、事件河流图等12类图表，同时提供标题，详情气泡、图例、值域、数据区域、时间轴、工具箱等7个可交互组件，支持多图表、组件的联动和混搭展现。&lt;/p&gt;

&lt;h3 id=&#34;5-基于bootstrap的用户端&#34;&gt;5. 基于Bootstrap的用户端&lt;/h3&gt;

&lt;p&gt;Bootstrap 是最受欢迎的 HTML、CSS 和 JS 框架，用于开发响应式布局、移动设备优先的 WEB 项目。为所有开发者、所有应用场景而设计。Bootstrap 让前端开发更快速、简单。所有开发者都能快速上手、所有设备都可以适配、所有项目都适用。&lt;/p&gt;

&lt;p&gt;预处理脚本：虽然可以直接使用 Bootstrap 提供的 CSS 样式表，但 Bootstrap 的源码是基于最流行的 CSS 预处理脚本 - Less 和 Sass 开发的。开发者可以采用预编译的 CSS 文件快速开发，也可以从源码定制自己需要的样式.。&lt;/p&gt;

&lt;p&gt;一个框架、多种设备：网站和应用能在 Bootstrap 的帮助下通过同一份代码快速、有效适配手机、平板、PC 设备，这一切都是 CSS 媒体查询（Media Query）的功劳。&lt;/p&gt;

&lt;p&gt;特性齐全：Bootstrap 提供了全面、美观的文档，可以轻松找到关于 HTML 元素、HTML 和 CSS 组件、jQuery 插件方面的所有详细文档。&lt;/p&gt;

&lt;p&gt;Bootstrap 是完全开源的。它的代码托管、开发、维护都依赖 GitHub 平台。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>